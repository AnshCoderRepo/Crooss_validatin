{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693a5536-9842-4edd-8a2e-9b34a8bf0987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X,y= datasets.load_iris(return_X_y=True)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02185598-fe00-45d1-895d-8a0c858b31fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 4), (60, 4), (90,), (60,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=0)#random_state=0 is used to ensure that the same split is produced each time the code is run.\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8552e6-680e-4880-a8eb-17391888b6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)# c=1 This paarameter controls the trade-off between achieving a low training error and a low testing error.\n",
    "clf.score(X_test, y_test)#returns the average accuracy score of the SVM classifier on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9491d09d-3ca3-468d-bb72-96a402b060a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97368421, 0.97297297, 0.97297297])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing cross valdiation metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf=svm.SVC(kernel='linear',C=1,random_state=42)\n",
    "scores=cross_val_score(clf,X,y,cv=4)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f77f8201-b20c-48a3-b417-11009097d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98 accuracy with a standard deviation of  0.01 \n"
     ]
    }
   ],
   "source": [
    "print(\"%0.2f accuracy with a standard deviation of % 0.2f \" %(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb6fc28-893b-4296-a52d-a2485a8b2efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97368421, 0.97297297, 0.97297297])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score \n",
    "from sklearn import metrics\n",
    "score= cross_val_score(clf,X,y,scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4046872d-906e-49b0-a72b-9a1d773488c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97777778, 0.97777778, 1.        , 0.95555556, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance:\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "n_samples=X.shape[0]\n",
    "cv=ShuffleSplit(n_splits=5, test_size=0.3,random_state=0)\n",
    "cross_val_score(clf,X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "865a09ec-06e4-47a7-a5d6-b657b277ace1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97333333])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another option is to use an iterable yielding (train, test) splits as arrays of indices, for example:\n",
    "def custom_cv_2folds(X):\n",
    "    n=X.shape[0]\n",
    "    i=1\n",
    "    while i<=2:\n",
    "        idx= np.arange(n*(i-1)/2,n*i/2,dtype=int)\n",
    "        yield idx,idx\n",
    "        i+=1\n",
    "\n",
    "custom_cv=custom_cv_2folds(X)\n",
    "cross_val_score(clf,X,y,cv=custom_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51c5d2c4-7077-4fc6-a107-2a68a5ea154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n"
     ]
    }
   ],
   "source": [
    "#Example of 2 fold cross Validation on a dataset with 4 samples:\n",
    "from sklearn.model_selection import KFold\n",
    "X=[\"a\",\"b\",\"c\",\"d\"]\n",
    "kf=KFold(n_splits=4)\n",
    "for train,test in kf.split(X):\n",
    "    print(\"%s %s\"%(train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fedf829-5936-449c-aa00-7177e720d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4] [1 3] \n",
      "[0 1 2 3] [4] \n",
      "[0 1 3 4] [2] \n",
      "[1 2 3 4] [0] \n",
      "[1 3 4] [0 2] \n",
      "[0 1 2 4] [3] \n",
      "[0 2 3 4] [1] \n",
      "[0 1 2 3] [4] \n"
     ]
    }
   ],
   "source": [
    "#Repeated K-Fold\n",
    "#Example of 2 fold k-fold repeatedd 2 time\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "X=np.array([[1,2],[3,4],[1,2],[3,4],[3,3]])\n",
    "random_state=12883823\n",
    "rkf=RepeatedKFold(n_splits=4,n_repeats=2,random_state=random_state)\n",
    "for train,test in rkf.split(X):\n",
    "    print(\"%s %s \" %(train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "519fdf35-047d-44a8-bbaf-a2a8e7ae37f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n"
     ]
    }
   ],
   "source": [
    "# leave One Out(LOO)\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "X=[1,2,3,4]\n",
    "loo=LeaveOneOut()\n",
    "for train,test in loo.split(X):\n",
    "    print(\"%s %s\" %(train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90d15f3e-7216-4f08-afba-da561a2c5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4] [0 1 2]\n",
      "[2 4] [0 1 3]\n",
      "[2 3] [0 1 4]\n",
      "[1 4] [0 2 3]\n",
      "[1 3] [0 2 4]\n",
      "[1 2] [0 3 4]\n",
      "[0 4] [1 2 3]\n",
      "[0 3] [1 2 4]\n",
      "[0 2] [1 3 4]\n",
      "[0 1] [2 3 4]\n"
     ]
    }
   ],
   "source": [
    "#Example of Leave-2-Out on a dataset with 4 samples:\n",
    "from sklearn.model_selection import LeavePOut\n",
    "X=np.ones(5)\n",
    "lpp=LeavePOut(p=3) # p value decides how much smaple will be in test ex if p=3 then test will have 3 data \n",
    "for train ,test in lpp.split(X):\n",
    "    print(\"%s %s\" %(train, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07db2ac6-d74e-4edc-be47-2c55f41d0be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 7 2 3 6 9 8] [4 1 5]\n",
      "[2 3 9 7 8 4 5] [1 6 0]\n",
      "[0 8 1 2 6 7 3] [4 9 5]\n",
      "[0 2 1 3 7 6 4] [5 9 8]\n"
     ]
    }
   ],
   "source": [
    "# Here is a usage example: of Random permutations cross-validation a.k.a. Shuffle & Split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "X=np.arange(10)\n",
    "ss=ShuffleSplit(n_splits=4,test_size=0.25,random_state=2)\n",
    "for train,test in ss.split(X):\n",
    "    print(\"%s %s\" %(train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "164588da-6b60-4eba-87e7-4671115142d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-[30  3] | test -[15  2]\n",
      "train-[30  3] | test -[15  2]\n",
      "train-[30  4] | test -[15  1]\n"
     ]
    }
   ],
   "source": [
    "#Stratified k-fold:-Here is an example of stratified 3-fold cross-validation on a dataset with 50 samples from two unbalanced classes. We show the number of samples in each class and compare with KFold.\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "X,y=np.ones((50,1)),np.hstack(([0]*45,[1]*5))\n",
    "skf=StratifiedKFold(n_splits=3)\n",
    "for train,test in skf.split(X,y):\n",
    "    print('train-{} | test -{}'.format(np.bincount(y[train]),np.bincount(y[test])))#np.bincount(y[train]): This part calculates the number of occurrences of each unique label in the training set (y[train]). It returns an array where the index represents the label, and the value represents the count of occurrences of that label in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82521145-7f33-4361-84f8-fff1fe499c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The numbers inside the square brackets represent the count of each label. For example, [45 5] means there are 45 samples with label 0 and 5 samples with label 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079b01c8-fb35-4c9e-98b3-e05b935d3b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2][3 4]\n",
      "[0 3 4][1 2]\n",
      "[1 2 3 4][0]\n"
     ]
    }
   ],
   "source": [
    "# Group K-fold -Imagine you have three subjects, each with an associated number from 1 to 3:\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "#X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
    "#y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]# labels \n",
    "#groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]# Groups for grouping k-fold\n",
    "# Example data: features, target, and groups\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([0, 0, 1, 1, 1])  # Binary classification labels\n",
    "groups = np.array([1, 2, 2, 3, 3])  # Groups for grouping k-fold\n",
    "gkf= GroupKFold(n_splits=3)\n",
    "for train,test in gkf.split(X,y,groups=groups):\n",
    "    print(\"%s%s\" % (train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8138f5-34d6-43a9-90fb-7564692156db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  6  7  8  9 10 12 13 14] [ 4  5 11 15 16 17]\n",
      "[ 0  2  3  4  5  6  7 10 11 12 13 14 15 16 17] [1 8 9]\n",
      "[ 0  1  4  5  6  7  8  9 11 12 13 14 15 16 17] [ 2  3 10]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 15 16 17] [12 13 14]\n",
      "[ 1  2  3  4  5  8  9 10 11 12 13 14 15 16 17] [0 6 7]\n"
     ]
    }
   ],
   "source": [
    "# example of StratifiedGroupKfold\n",
    "# intance:-Each instance represents a single occurrence or sample of the data being analyzed.\n",
    "#instances are often represented as rows in a dataset, where each row contains information about a specific entity or observation.\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "X=list(range(18))\n",
    "y=[1]*6 +[0]*12# 6 instance of class 1 and 12 instances of class 0 of target class\n",
    "groups=[1,2,3,3,4,4,1,1,2,2,3,4,5,5,5,6,6,6]\n",
    "sgkf=StratifiedGroupKFold(n_splits=5)\n",
    "for train,test in sgkf.split(X,y, groups=groups):\n",
    "    print(\"%s %s\" %(train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ad4b36-51eb-4da0-b6a1-925810a1139d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6] [0 1]\n",
      "[0 1 4 5 6] [2 3]\n",
      "[0 1 2 3] [4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Leave one group out :-\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "X=[1,5,10,50,60,70,80]\n",
    "y=[0,1,1,2,2,2,2] # target variable\n",
    "groups=[1,1,2,2,3,3,3]\n",
    "logo=LeaveOneGroupOut()\n",
    "for train,test in logo.split(X,y, groups=groups):\n",
    "    print(\"%s %s\" %(train, test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71fde75b-8d0b-48ae-a0f3-e166e36bcf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5][0 1 2 3]\n",
      "[2 3][0 1 4 5]\n",
      "[0 1][2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# Leave P Group out cross- validation\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "X=np.arange(6)\n",
    "y=[1,1,1,2,2,2]\n",
    "groups=[1,1,2,2,3,3]\n",
    "lpgo=LeavePGroupsOut(n_groups=2)\n",
    "for  train, test in lpgo.split(X,y, groups=groups):\n",
    "    print(\"%s%s\"%(train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb266767-b3aa-4137-9576-b76b1f977e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3] [4 5 6 7]\n",
      "[2 3 6 7] [0 1 4 5]\n",
      "[2 3 4 5] [0 1 6 7]\n",
      "[4 5 6 7] [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Here is a usage example of Group Shuffle Split:\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"]\n",
    "groups = [1, 1, 2, 2, 3, 3, 4, 4]\n",
    "gss=GroupShuffleSplit(n_splits=4,test_size=0.5, random_state=0)\n",
    "for train,test in gss.split(X,y,groups=groups):\n",
    "    print(\"%s %s\" %(train,test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5753962-cd85-4586-8781-9303b72629f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6,), (2,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.2.5. Using cross-validation iterators to split train and test\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "X = np.array([0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001])\n",
    "y = np.array([\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"])\n",
    "groups = np.array([1, 1, 2, 2, 3, 3, 4, 4])\n",
    "\n",
    "train_indx,test_indx=next(GroupShuffleSplit(random_state=7).split(X,y,groups))\n",
    "X_train,X_test,y_train,y_test=X[train_indx],X[test_indx],y[train_indx],y[test_indx]\n",
    "X_train.shape,X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "224bca0b-c6e4-4419-9797-3ca5ce2452b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 4]), array([3]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(groups[train_indx]),np.unique(groups[test_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b847f60-8ff3-4d25-ba1d-046e913de78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)\n"
     ]
    }
   ],
   "source": [
    "# Example of 3-split time series cross-validation on a dataset with 6 samples:\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv=TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e16c26cd-f70c-4c0a-91b7-6debf45dd721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] [3] \n",
      "[0 1 2 3] [4] \n",
      "[0 1 2 3 4] [5] \n"
     ]
    }
   ],
   "source": [
    "for train,test in tscv.split(X):\n",
    "    print(\"%s %s \" %(train,test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cba44d-fe2a-4890-ae26-ebb716271ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
